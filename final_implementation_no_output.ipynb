{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the maps from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_30GHz.fits\"\n",
    "filename2 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_44GHz.fits\"\n",
    "filename3 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_70GHz.fits\"\n",
    "filename4 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_100GHz.fits\"\n",
    "filename5 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_143GHz.fits\"\n",
    "filename6 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_145GHz.fits\"\n",
    "filename7 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_217GHz.fits\"\n",
    "filename8 = \"/moto/hill/projects/actpol/SO_Sims_LAMBDA/d56/SO_skymaps_deep56/so_skymap_deep56_353GHz.fits\"\n",
    "\n",
    "imap30 = enmap.read_map(filename1)\n",
    "imap44 = enmap.read_map(filename2)\n",
    "imap70 = enmap.read_map(filename3)\n",
    "imap100 = enmap.read_map(filename4)\n",
    "imap143 = enmap.read_map(filename5)\n",
    "imap145 = enmap.read_map(filename6)\n",
    "imap217 = enmap.read_map(filename7)\n",
    "imap353 = enmap.read_map(filename8)\n",
    "\n",
    "print(\"Map shape and dtype (same for all the maps):\")\n",
    "print(imap44.shape, imap44.dtype)\n",
    "\n",
    "fmap30 = np.ndarray.flatten(imap30)\n",
    "fmap44 = np.ndarray.flatten(imap44)\n",
    "fmap70 = np.ndarray.flatten(imap70)\n",
    "fmap100 = np.ndarray.flatten(imap100)\n",
    "fmap143 = np.ndarray.flatten(imap143)\n",
    "fmap145 = np.ndarray.flatten(imap145)\n",
    "fmap217 = np.ndarray.flatten(imap217)\n",
    "fmap353 = np.ndarray.flatten(imap353)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the R Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The r matrix is a matrix of size (n_map X n_map), where each entry is the sum of the multiplied entries of the specified indices in map_array, which is then divided by n_pix. Note that each entry in map_array is the corresponding flattened map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros([n_map,n_map])\n",
    "\n",
    "for i in range(n_map):\n",
    "    for j in range(n_map):\n",
    "        r[i][j] = np.sum((map_array[i] * map_array[j])) / n_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the B Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The b matrix here is a 3D matrix of size (n_map X n_map X n_map), where each entry is the sum of the product of the corresponding flattened map, now with another dimension represented by k, and is still divided by n_pix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros([n_map,n_map,n_map])\n",
    "\n",
    "for i in range(n_map):\n",
    "    for j in range(n_map):\n",
    "        for k in range(n_map):\n",
    "            b[i][j][k] = np.sum(map_array[i] * map_array[j] * map_array[k]) / n_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Arrays as Files to Reduce Memory Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.save('r_arr',r)\n",
    "numpy.save('b_arr',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('imap30',imap30)\n",
    "np.save('imap44',imap44)\n",
    "np.save('imap70',imap70)\n",
    "np.save('imap100',imap100)\n",
    "np.save('imap143',imap143)\n",
    "np.save('imap145',imap145)\n",
    "np.save('imap217',imap217)\n",
    "np.save('imap353',imap353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('map30',fmap30)\n",
    "np.save('map44',fmap44)\n",
    "np.save('map70',fmap70)\n",
    "np.save('map100',fmap100)\n",
    "np.save('map143',fmap143)\n",
    "np.save('map145',fmap145)\n",
    "np.save('map217',fmap217)\n",
    "np.save('map353',fmap353)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT RUN CODE ABOVE THIS CELL\n",
    "All the code in the above cells is for informational purposes i.e. displaying how the R and B matrices were initially constructed, and method for saving files so that may be loaded in using the given file name (all files use the .npy extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages for performing the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random\n",
    "import statistics\n",
    "from statistics import mean, pvariance\n",
    "import scipy\n",
    "from scipy.optimize import minimize,NonlinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages for performing map manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pixell import enmap,utils\n",
    "import matplotlib.pyplot as plt\n",
    "from pixell import enplot\n",
    "import os,sys\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Unflattened Map Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unflattened maps are used later on to show CMB maps. For now, the data works with flattened maps, particularly to build the R and B matrices displayed in the cells above. They have alerady been built, saved, and are loaded in 'map_array' below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each map shape represents the number of total pixels, which is of the form (2182,9455,1) and dim=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imap30 = np.load('imap30.npy')\n",
    "imap44 = np.load('imap44.npy')\n",
    "imap70 = np.load('imap70.npy')\n",
    "imap100 = np.load('imap100.npy')\n",
    "imap143 = np.load('imap143.npy')\n",
    "imap145 =  np.load('imap145.npy')\n",
    "imap217 = np.load('imap217.npy')\n",
    "imap353 = np.load('imap353.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Matrix Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.load('r_arr.npy')\n",
    "b = np.load('b_arr.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Î”T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the number of maps, number of total pixels, and flattened maps (which are now 1D numpy arrays), as this was necessary for building the matrices and other computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_map = 8\n",
    "n_pix = 2182*9455\n",
    "map_array = [np.load('map30.npy'),np.load('map44.npy'),np.load('map70.npy'),np.load('map100.npy'),np.load('map143.npy'),np.load('map145.npy'),np.load('map217.npy'),np.load('map353.npy')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.array([.125,.125,.125,.125,.125,.125,.125,.125])\n",
    "a = np.ones(len(w0))\n",
    "\n",
    "#defines a lambda function that returns dot product of weights and array of ones\n",
    "fun = lambda w: np.dot(w,a)\n",
    "\n",
    "print(\"The sum of all the weights is:\")\n",
    "print(fun(w0))\n",
    "\n",
    "#nonlinear constraint that implements the function and sets the constraint bounds\n",
    "con = NonlinearConstraint(fun,1,1)\n",
    "\n",
    "#defines a lambda function that implements the variance equation\n",
    "var = lambda w: np.dot(np.dot(w,r),w)\n",
    "\n",
    "print(\"The variance is:\")\n",
    "print(var(w0))\n",
    "\n",
    "#minimization method ()\n",
    "mini = minimize(var,w0,method='SLSQP',constraints=con)\n",
    "weights_var = mini.x\n",
    "print(mini.x)\n",
    "\n",
    "print()\n",
    "print(var(mini.x))\n",
    "\n",
    "print()\n",
    "print(fun(mini.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(len(w0))\n",
    "\n",
    "#defines a lambda function that returns dot product of weights and array of ones\n",
    "fun = lambda w: np.dot(w,a)\n",
    "\n",
    "print(\"The sum of all the weights is:\")\n",
    "print(sum(w0))\n",
    "\n",
    "#nonlinear constraint that implements the function and sets the constraint bounds\n",
    "con = NonlinearConstraint(fun,1,1)\n",
    "\n",
    "#defines a lambda function that implements the variance equation\n",
    "skew = lambda w: abs(np.dot(np.dot(np.dot(w,b),w), w))\n",
    "\n",
    "#minimization method\n",
    "n_iter = 100\n",
    "min_skew_arr = np.zeros(n_iter)\n",
    "min_skew_weights_arr = np.zeros((n_iter,8))\n",
    "for i in range(n_iter):\n",
    "    w0 = np.random.dirichlet(np.ones(8),size=1)[0]\n",
    "    mini = minimize(skew,w0,method='SLSQP',constraints=con)\n",
    "    \n",
    "    weights_skew = mini.x\n",
    "    skewness_val = skew(mini.x)\n",
    "    \n",
    "    min_skew_weights_arr[i] = weights_skew\n",
    "    min_skew_arr[i] = skewness_val\n",
    "    \n",
    "min_skew_val = np.argmin(min_skew_arr) #can plot array values\n",
    "\n",
    "print()\n",
    "print(\"The smallest skewness value for 100 iterations is:\")\n",
    "print(min_skew_arr[min_skew_val])\n",
    "print()\n",
    "print(\"The solution array at the smallest skewness value is:\")\n",
    "print(min_skew_weights_arr[min_skew_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imap_array = np.array([imap30,imap44,imap70,imap100,imap143,imap145,imap217,imap353])\n",
    "\n",
    "yp_var = imap30.copy()\n",
    "yp_var *= 0.\n",
    "\n",
    "for i in range(n_map):\n",
    "    yp_var += imap_array[i]*weights_var[i]\n",
    "    \n",
    "print(yp_var)\n",
    "\n",
    "yp_skew = imap30.copy()\n",
    "yp_skew *= 0\n",
    "\n",
    "for i in range(n_map):\n",
    "    yp_skew += imap_array[i]*weights_skew[i]\n",
    "\n",
    "print(yp_skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map of the Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = enplot.plot(yp_var, range=300,mask=0)\n",
    "\n",
    "def eshow(x,**kwargs): enplot.show(enplot.plot(x,**kwargs))\n",
    "eshow(yp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map of the Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = enplot.plot(yp_skew, range=300,mask=0)\n",
    "\n",
    "def eshow(x,**kwargs): enplot.show(enplot.plot(x,**kwargs))\n",
    "eshow(yp_skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map of the (Variance - Skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = enplot.plot(yp_var-yp_skew, range=300,mask=0)\n",
    "\n",
    "def eshow(x,**kwargs): enplot.show(enplot.plot(x,**kwargs))\n",
    "eshow(yp_var-yp_skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the Variance and Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = np.array([30,44,70,100,143,145,217,353])\n",
    "\n",
    "diff = weights_var - (weights_skew / 10)\n",
    "plt.plot(freq, abs(diff))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the Sets of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = np.array([30,44,70,100,143,145,217,353])\n",
    "\n",
    "plot = plt.plot(freq, weights_var,'b-',freq,weights_skew/10,'r')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Variance and Skewness')\n",
    "plt.legend(['Variance','Skewness / 10'])\n",
    "plt.show()\n",
    "print(\"Note that the skewness weights are reduced to a tenth of their original value to better compare to the variance weights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing for Both Variance and Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 100\n",
    "a = np.ones(len(w0))\n",
    "\n",
    "#defines a lambda function that returns dot product of weights and array of ones\n",
    "fun = lambda w: np.dot(w,a)\n",
    "\n",
    "#nonlinear constraint that implements the function and sets the constraint bounds\n",
    "con = NonlinearConstraint(fun,1,1)\n",
    "\n",
    "x_arr = []\n",
    "vy_arr = []\n",
    "sy_arr = []\n",
    "#minimization method\n",
    "def multi_mini(x,y):\n",
    "    min_combo_weights_arr = np.zeros((n_iter,8))\n",
    "    min_combo_arr = np.zeros(n_iter)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        w0 = np.random.dirichlet(np.ones(8),size=1)[0]\n",
    "    \n",
    "        #defines a lambda function that implements the variance equation\n",
    "        var = lambda w: np.dot(np.dot(w,r),w)\n",
    "        skew = lambda w: abs(np.dot(np.dot(np.dot(w,b),w), w))\n",
    "        combo_func = lambda w: x*var(w) + y*skew(w)\n",
    "    \n",
    "        minimum = minimize(combo_func,w0,method='SLSQP',constraints=con)\n",
    "        \n",
    "        weights_combo = mini.x\n",
    "        combo_val = combo_func(mini.x)\n",
    "    \n",
    "        min_combo_weights_arr[i] = weights_combo\n",
    "        min_combo_arr[i] = combo_val\n",
    "        \n",
    "    #appends to x and var/skew arrays after finding smallest var/skew   \n",
    "    x_arr.append(x)\n",
    "    vy_arr.append(var(minimum.x))\n",
    "    sy_arr.append(skew(minimum.x))\n",
    "        \n",
    "    min_combo_val = np.argmin(min_skew_arr)\n",
    "    \n",
    "    #checking that the var and skew arrays are the same as the combined arrays when the weights eliminate one statistic\n",
    "    if (x == 1 and y == 0):\n",
    "        if (weights_var.all() == minimum.x.all()):\n",
    "            print(\"Variance end-checker: passed\")\n",
    "        else:\n",
    "            print(\"Variance end-checker: failed\")\n",
    "    if (x == 0 and y == 1):\n",
    "        if (weights_skew.all() == minimum.x.all()):\n",
    "            print(\"Skewness end-checker: passed\")\n",
    "        else:\n",
    "            print(\"Skewness end-checker: failed\")\n",
    "            \n",
    "    print()\n",
    "    print(\"Variance weight:\")\n",
    "    print(x)\n",
    "    print(\"Skewness weight:\")\n",
    "    print(y)\n",
    "    #print(\"The solution array for the given linear combination of var and skew:\")\n",
    "    #print(minimum.x)\n",
    "    print(\"Variance:\")\n",
    "    print(var(minimum.x))\n",
    "    print(\"Skewness:\")\n",
    "    print(skew(minimum.x))\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "multi_mini(0,1)\n",
    "multi_mini(.5,.5)\n",
    "multi_mini(.7,.3)\n",
    "multi_mini(.8,.2)\n",
    "multi_mini(.85,.15)\n",
    "multi_mini(.9,.1)\n",
    "multi_mini(.95,.05)\n",
    "multi_mini(.96,.04)\n",
    "multi_mini(.969,.031)\n",
    "multi_mini(.97,.03)\n",
    "multi_mini(.971,.029)\n",
    "multi_mini(1,0)\n",
    "#x-axis = x\n",
    "#y-axis = var/skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the Minimum Variance Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_arr, vy_arr)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(\"Weighted Variance\")\n",
    "plt.ylabel(\"Minimum Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the Minimum Skewness Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_arr, sy_arr)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel('Weighted Variance')\n",
    "plt.ylabel('Minimum Skewness')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
